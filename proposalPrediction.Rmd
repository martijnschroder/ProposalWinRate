---
title: "Predicting proposal win rates"
author: "Martijn Schroder"
date: "1/05/2019"
output:
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
  html_notebook:
    fig_caption: yes
    toc: yes
---
```{r load requiredlibraries, include=FALSE}
library(tidyverse)
# library(dplyr)
library(lubridate)
library(ggthemes)
library(tibble)
library(gridExtra)
library(caret)
library(knitr)
library(kableExtra)
```


```{r load dataset, include=FALSE}
# Read the dataset
proposals <- read_csv("data/data.csv", col_names = TRUE)
```


# Executive summary
In management consulting competitiveness is high. Our firm competes actively with the 'Big 4' consultancies. Better understanding of the reasons why we win and lose proposal will give us an advantage.

Our business makes decisions on our proposal management practice with the view to increase win rates. Until recently those decisions were made based on personal experiences and perception of what works and what doesn't.

In this assignment my aim is to try machine learning approaches to gain insights into what the data tells us about the relevant features that are good predictors of win and lose rates.

Given the low number of transactions and limited cleanliness of the data, the analysis of features that should underpin decisions around proposals is relatively ambiguous. This is the main challenge to work with.

> For obvious reasons the data is de identified and various columns have been recoded. This part of the data wrangling has not been shown.

## Goal
The goal of this assignment is to try and predict wether proposals will be won or lost, given a set of features.

## Key steps
The following steps were taken:

  1. Investigate data and cleanse where required
  2. Prepare data and explore
  3. Study suitability of machine learning approaches and select a method
  4. Train chosen model and evaluate performance with training set
  5. Interpret results and draw conclusions

## Results



# Cleaning data
The data set is a raw export from the system used to manage opportunities. A csv export was obtained, which after de identification has the following structure:

```{r names and structure raw dataset, echo=TRUE}
str(proposals, give.attr = FALSE) # show structure of data
```

## Description of dataset
The meaning of the columns is as follows:
```{r create and show table explanation of dataset, echo=FALSE}
# Create a pretty table explaining the data in the dataset

df_col_names <- names(proposals)
df_meaning <- c("Name of the account, i.e. the client",
                "Proposal win / loss (1 = win, 0 = loss)",
                "Estimated value of the opportunity",
                "Creation date of the record",
                "Close date of the record",
                "High level practice group for the opportunity",
                "Business offer the opportunity falls under (e.g. analytics, consulting, project management)",
                "Sector of business the client falls under (e.g. education, health, finance)",
                "Segment of the sector the opportunity falls under (e.g. insurance or loans for sector finance",
                "Proposal director; in our practice we assign a proposal director and manager to each proposal",
                "Proposal manager",
                "Source of the opportunity, i.e. how did we know of it (e.g. approached by client, tender",
                "Level of competitiveness of the opportunity (i.e. are we only party bidding or are there more?)",
                "Three letter code significing the account"
                )
df <- tibble(df_col_names, df_meaning)
names(df) <- c("Column", "Description")

# Print the pretty table
df %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

rm(df, df_col_names, df_meaning)
```

## Fixing data formats
The data needs cleaning up. The following changes are made:

* Convert "amount" column from num to double
* Convert "creationDate" and "closeDate" to Date format

```{r re code data types, cache=TRUE}
# Change data types for amount, creationDate and closeDate
proposals$amount <- as.double(proposals$amount)
proposals$creationDate <- as.Date(proposals$creationDate, "%d/%m/%y")
proposals$closeDate <- as.Date(proposals$closeDate, "%d/%m/%y")
```


# Exploration
## Exploration of columns
Some basic exploration of the columns to better understand what information is useful, given business rules.

## Data integrity
The figure below shows the proportion of NA values in the columns of the dataset. 

```{r NA values in dataset, echo=FALSE}
# Step 1: create a tibble with column names and proportions of NA values per column
n <- nrow(proposals) # number of rows in dataset
sumNAbefore <- tibble(colSums(is.na(proposals)/n)) # proportions of NA values per column
sumNAbefore <- cbind(colnames(proposals), sumNAbefore) # concatenate the vectors
names(sumNAbefore) <- c("feature", "proportion") # rename the columns to human readible

# plot NA proportions
sumNAbefore %>% ggplot(aes(reorder(feature, -proportion), proportion)) +
  geom_bar(stat = "Identity") +
  coord_flip() +
  xlab("Dataset column") +
  ylab("Proportion of NA values") +
  ggtitle("Proportion of NA values in the dataset") +
  theme_light()

rm(n, sumNAbefore)
```

The following approaches to addressing the NA values are implemented:

* *competitiveness*: drop the column. Although it would be interesting to see the impact of competitiveness on proposals, too many data points are missing to make it useful in the overall analysis. Business practice changes will need to ensure this data is consistently gathered going forward
```{r drop competitiveness column}
proposals <- proposals %>% select(-competitiveness)
```


* *Amount*: Replace missing amounts with overall mean for amount, or if group means can be used (e.g. group means for *offer*). The distribution of amount and boxplots for win and loss data show significant outliers for amount. Potentially predictive analysis will need to take into account potential differences in win rates given amount of proposals
```{r summary of proposals$amount}
summary(proposals$amount)

temp <- proposals
temp$stage[temp$stage == 1] <- "win"
temp$stage[temp$stage == 0] <- "loss"

temp %>%
  ggplot(aes(practice, amount)) +
  geom_boxplot() +
  theme_light() +
  facet_wrap(~stage, ncol=2) +
  ggtitle("Win / Loss boxplots over amount") +
  xlab("Practices") +
  ylab("Amount")

rm(temp)
```


```{r replace missing amounts with overall group means}
amounts <- as.double(proposals$amount[!is.na(proposals$amount)])
avg_amount <- mean(amounts[amounts > 999]) # calculate overall avg with values greater than 999
proposals$amount[is.na(proposals$amount)] <- avg_amount # replace NAs with avg amount
proposals$amount[proposals$amount <= 999] <- avg_amount # replace amounts < 999 with avg_amount
rm(amounts, avg_amount)
```

* *Proposal director / manager*: retain the NA values as they represent uncertainty in the dataset. Replacing them with for example "Unknown", would reduce uncertainty artificially

* *Sector*: there are `r sum(is.na(proposals$source))` NA values. Substitute NA values with "unknown"
```{r change NA values for source into "unknown"}
proposals$sector[is.na(proposals$sector)] <- "unknown"
```

* *Segment*: there are `r sum(is.na(proposals$segment))` NA values. We can potentially match offer data for observations with segment data and substitute missing values. Alternatively we leave NA values

* *Source*: there are `r sum(is.na(proposals$sector))` NA values. A quick analysis shows that there is significant predictive value in source for win/loss rates. Although many values are missing, we can try and see if a relation exists between source and other features:
   * 
```{r win/loss rates given source}
# proportion of winning proposals given source
sum_tab <- proposals %>%
  group_by(source, stage) %>%
  summarise(n = n(), value = sum(amount)) %>%
  ungroup() %>%
  group_by(source) %>%
  mutate(p = n / sum(n))

p1 <- sum_tab %>%
  filter(stage == 1) %>%
  ggplot(aes(reorder(source, p), p)) +
  coord_flip() +
  geom_bar(stat = "Identity") +
  xlab("Source of proposal") +
  ylab("Proportion of proposals won")

p2 <- sum_tab %>%
  filter(stage == 1) %>%
  ggplot(aes(n, p, colour=source)) +
  geom_point() +
  xlab("Number of proposals") +
  ylab("Win rate")

grid.arrange(p1, p2, ncol = 2)
rm(p1, p2, sum_tab)
```
As can be seen, the variability of win rates given sources is based on small numbers of observations. Win rates ordered by number of observations they're based on shows the following the following:

```{r win rates ordered by number of observations}
# table of win rates given number of observations
proposals %>%
  group_by(source, stage) %>%
  summarise(n = n(), value = sum(amount)) %>%
  ungroup() %>%
  group_by(source) %>%
  mutate(p_win = n / sum(n)) %>%
  filter(stage == 1) %>%
  arrange(desc(n)) %>%
  select(n, p_win, source)

```
Source2 has significantly more observations than any other sources (all n <= 10 not printed). Source can be used as a predictor, however for source NA values in the dataset we will need to substitute with overall win rate for NAs if possible.


## Data exploration
First some basic exploration of the data to get an understanding of what it tells us.



# Method

1. Get dataset ready for analysis
2. Try various ML approaches
3. Select potential model
4. Conduct analysis

# Analysis
Split data in a train and test set. The train set will contain 90% of the data.
```{r create train and test set}
# Create train and test set with standard seed for reproducibiliy
set.seed(1)

# Get a random sample of 90% for the train set and 10% for validation
train_index <- sample(1:nrow(proposals), round(0.9*nrow(proposals)))
train_set <- proposals[train_index, ]
test_set <- proposals[-train_index, ]

# clean up environment
rm(train_index) # clean up
```


## glm

## tree



## K nearest neighbours
K nearest neightbour performs well
```{r K nearest neighbours, cache=TRUE}
# K nearest neighbours
library(caret)

train_set_knn <- train_set %>%
  na.omit() %>%
  select(-creationDate, -closeDate, -account, -amount, -director, -manager)

test_set_knn <- train_set %>%
  na.omit() %>%
  select(-creationDate, -closeDate, -account, -amount, -director, -manager)


train_knn <- train(stage ~ ., method = "knn", 
                   data = train_set_knn,
                   na.action = na.pass,
                   tuneGrid = data.frame(k = seq(9, 71, 2)))

# best tune
train_knn$bestTune

confusionMatrix(predict(train_knn, test_set_knn, type = "raw"),
                test_set_knn$stage)$overall["Accuracy"]

```

Best accuracy: 0.7006897 

Are some pairs of directors and managers better than others?
```{r compare directors and managers as pairs}
# TODO
```


## rmse

## 


# Conclusions
