---
title: "Predicting proposal win rates"
author: "Martijn Schroder"
date: "1/05/2019"
output:
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    toc: yes
  html_notebook:
    fig_caption: yes
    toc: yes
---
```{r load requiredlibraries, include=FALSE}
library(tidyverse)
library(lubridate)
library(ggthemes)
library(tibble)
library(gridExtra)
library(caret)
library(knitr)
library(kableExtra)
```


```{r load dataset, include=FALSE}
# Read the dataset
proposals <- read_csv("data/data.csv", col_names = TRUE)
```


# Executive summary
In management consulting competitiveness is high. Our firm competes actively with the 'Big 4' consultancies. Better understanding of the reasons why we win and lose proposal will give us an advantage in the market.

Our business makes decisions on our proposal management practice with the view to increase win rates. Until recently those decisions were made based on personal experiences and perception of what works and what doesn't.

In this assignment my aim is to try machine learning approaches to gain insights into what the data tells us about the relevant features that are good predictors of win and lose rates.

Given the low number of transactions and limited cleanliness of the data, the analysis of features that should underpin decisions around proposals is relatively ambiguous. This is the main challenge to work with.

> For obvious reasons the data is de identified and various columns have been recoded. This part of the data wrangling has not been shown.

## Goal
The goal of this assignment is to try and predict wether proposals will be won or lost, given a set of features.

## Key steps
The following steps were taken:

  1. Investigate data and cleanse where required
  2. Prepare data and explore
  3. Study suitability of machine learning approaches and select a method
  4. Train chosen model and evaluate performance with training set
  5. Interpret results and draw conclusions

## Results
The high number of categorical variables made this a challenging tasks in terms of applying machine learning approaches.

Good predictions were achieved with fitting K nearest neighbours. Regression based approaches performed reasonable. All models were hard to interpret in terms of the causes of win rates.

Most significant finding was that our dataset could be improved through adding featuers that are quantified. Added these features will allow for further exploration of predictors of win rates, but will require changes in our porposal management practice. Examples of new features include:

* Subjective estimation of degree of confidence to win a proposal by sector experts
* Subjective estimation of the strength of the relationship with the client
* **more points**

After gathering production data, it will then be possible to study of those features are good predictors of proposal win rates.

The main reasons why we win proposals seem to include:

* Amount of the proposal
* 

Features I expected to have a clear impact, but didn't included:

* the directors and managers working on the proposal
* the amount of past proposals won as a preduction of future win rates
* **more points**

# Cleaning data
The data set is a raw export from the system used to manage opportunities. A csv export was obtained, which after de identification has the following structure:

```{r names and structure raw dataset, echo=TRUE}
str(proposals, give.attr = FALSE) # show structure of data
```

## Description of dataset and cleaning
The meaning of the columns is as follows:
```{r create and show table explanation of dataset, echo=FALSE}
# Create a pretty table explaining the data in the dataset

df_col_names <- names(proposals)
df_meaning <- c("Name of the account, i.e. the client",
                "Proposal win / loss (1 = win, 0 = loss)",
                "Estimated value of the opportunity",
                "Creation date of the record",
                "Close date of the record",
                "High level practice group for the opportunity",
                "Business offer the opportunity falls under (e.g. analytics, consulting, project management)",
                "Sector of business the client falls under (e.g. education, health, finance)",
                "Segment of the sector the opportunity falls under (e.g. insurance or loans for sector finance",
                "Proposal director; in our practice we assign a proposal director and manager to each proposal",
                "Proposal manager",
                "Source of the opportunity, i.e. how did we know of it (e.g. approached by client, tender",
                "Level of competitiveness of the opportunity (i.e. are we only party bidding or are there more?)",
                "Three letter code significing the account"
                )
df <- tibble(df_col_names, df_meaning)
names(df) <- c("Column", "Description")

# Print the pretty table
df %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

rm(df, df_col_names, df_meaning)
```

## Fixing data formats
The data needs cleaning up. The following changes are made:

* Convert "amount" column from num to double
* Convert "creationDate" and "closeDate" to Date format

```{r re code data types, cache=TRUE}
# Change data types for amount, creationDate and closeDate
proposals$amount <- as.double(proposals$amount)
proposals$creationDate <- as.Date(proposals$creationDate, "%d/%m/%y")
proposals$closeDate <- as.Date(proposals$closeDate, "%d/%m/%y")
```


# Exploration
## Exploration of columns
Some basic exploration of the columns to better understand what information is useful, given business rules.

## Data integrity
The figure below shows the proportion of NA values in the columns of the dataset. 

```{r NA values in dataset, echo=FALSE}
# Step 1: create a tibble with column names and proportions of NA values per column
n <- nrow(proposals) # number of rows in dataset
sumNAbefore <- tibble(colSums(is.na(proposals)/n)) # proportions of NA values per column
sumNAbefore <- cbind(colnames(proposals), sumNAbefore) # concatenate the vectors
names(sumNAbefore) <- c("feature", "proportion") # rename the columns to human readible

# plot NA proportions
sumNAbefore %>% ggplot(aes(reorder(feature, -proportion), proportion)) +
  geom_bar(stat = "Identity") +
  coord_flip() +
  xlab("Dataset column") +
  ylab("Proportion of NA values") +
  ggtitle("Proportion of NA values in the dataset") +
  theme_light()

rm(n, sumNAbefore)
```

The following approaches to addressing the NA values are implemented:

* *competitiveness*: drop the column. Although it would be interesting to see the impact of competitiveness on proposals, too many data points are missing to make it useful in the overall analysis. Business practice changes will need to ensure this data is consistently gathered going forward
```{r drop competitiveness column}
proposals <- proposals %>% select(-competitiveness)
```


* *Amount*: Replace missing amounts with overall mean for amount, or if group means can be used (e.g. group means for *offer*). The distribution of amount and boxplots for win and loss data show significant outliers for amount. Potentially predictive analysis will need to take into account potential differences in win rates given amount of proposals
```{r summary of proposals$amount}
summary(proposals$amount)

temp <- proposals
temp$stage[temp$stage == 1] <- "win"
temp$stage[temp$stage == 0] <- "loss"

temp %>%
  ggplot(aes(practice, amount)) +
  geom_boxplot() +
  theme_light() +
  facet_wrap(~stage, ncol=2) +
  ggtitle("Win / Loss boxplots over amount") +
  xlab("Practices") +
  ylab("Amount")

rm(temp)
```


```{r replace missing amounts with overall group means}
amounts <- as.double(proposals$amount[!is.na(proposals$amount)])
avg_amount <- mean(amounts[amounts > 999]) # calculate overall avg with values greater than 999
proposals$amount[is.na(proposals$amount)] <- avg_amount # replace NAs with avg amount
proposals$amount[proposals$amount <= 999] <- avg_amount # replace amounts < 999 with avg_amount
rm(amounts, avg_amount)
```

* *Proposal director / manager*: there are only 3 observations with NA values for proposal director and manager. For simplicity sake we'll delete those.
```{r remove observations with NA values for director and manager}
# observations with NA values for director or manager
proposals[is.na(proposals$director) | is.na(proposals$manager), ]

# delete the offending observations
proposals <- proposals[!(is.na(proposals$director) | is.na(proposals$manager)), ]
```


* *Sector*: there are `r sum(is.na(proposals$source))` NA values. Substitute NA values with "unknown"
```{r change NA values for source into "unknown"}
proposals$sector[is.na(proposals$sector)] <- "unknown"
```

* *Segment*: there are `r sum(is.na(proposals$segment))` NA values. We can potentially match offer data for observations with segment data and substitute missing values. Alternatively we leave NA values. Proposal managers have the responsibility to enter proposal data in our system. Are there any serial offenders in terms of data quality?

```{r fix NA values for segment}
proposals[is.na(proposals$segment), ] %>% select(account, practice, sector, segment, offer) %>% arrange(sector) %>% group_by(offer) %>% summarise(n = n()) %>% arrange(desc(n))

# It looks like there's no serial offenders. Just limited clarity of process
proposals[is.na(proposals$segment), ] %>% select(account, practice, sector, segment, offer, manager) %>% group_by(manager) %>% summarise(n = n()) %>% arrange(desc(n)) %>% filter(n>2) %>% ggplot(aes(reorder(manager, n), n)) + geom_bar(stat="Identity") + coord_flip()

# Fix the offending entries
proposals$segment[is.na(proposals$segment)] <- "unknown"
```


* *Source*: there are `r sum(is.na(proposals$sector))` NA values. A quick analysis shows that there is significant predictive value in source for win/loss rates. Although many values are missing, we can try and see if a relation exists between source and other features:
   * 
```{r win/loss rates given source}
# proportion of winning proposals given source
sum_tab <- proposals %>%
  group_by(source, stage) %>%
  summarise(n = n(), value = sum(amount)) %>%
  ungroup() %>%
  group_by(source) %>%
  mutate(p = n / sum(n))

p1 <- sum_tab %>%
  filter(stage == 1) %>%
  ggplot(aes(reorder(source, p), p)) +
  coord_flip() +
  geom_bar(stat = "Identity") +
  xlab("Source of proposal") +
  ylab("Proportion of proposals won")

p2 <- sum_tab %>%
  filter(stage == 1) %>%
  ggplot(aes(n, p, colour=source)) +
  geom_point() +
  xlab("Number of proposals") +
  ylab("Win rate")

grid.arrange(p1, p2, ncol = 2)
rm(p1, p2, sum_tab)
```
As can be seen, the variability of win rates given sources is based on small numbers of observations. Win rates ordered by number of observations they're based on shows the following the following:

```{r win rates ordered by number of observations}
# table of win rates given number of observations
proposals %>%
  group_by(source, stage) %>%
  summarise(n = n(), value = sum(amount)) %>%
  ungroup() %>%
  group_by(source) %>%
  mutate(p_win = n / sum(n)) %>%
  filter(stage == 1) %>%
  arrange(desc(n)) %>%
  select(n, p_win, source)

```
Source2 has significantly more observations than any other sources (all n <= 10 not printed). Source can be used as a predictor, however for source NA values in the dataset we could substitute with overall win rate for NAs. Alternatively we create a new source, called "unknown". That is the path we'll follow.
```{r substitute source NA values with "unknown"}
proposals$source[is.na(proposals$source)] <- "unknown"
```

* *code*: `r sum(is.na(proposals$code))` entries are NA values. Recode those to "unknown"
```{r remove NA values from code}
proposals$code[is.na(proposals$code)] <- "unknown"
```


## Data exploration
First some basic exploration of the data to get an understanding of what it tells us.

* **Average win rate by account**
```{r average win rate by account}
# average win rate by account
proposals %>%
  group_by(account, stage) %>%
  summarise(n = n()) %>% # total number of wins and losses by account
  ungroup() %>%
  group_by(account) %>%
  mutate(p = n / sum(n)) %>% # proportions win/loss by account
  filter(n>9, stage == 1) %>% # remove small n and select wins only
  arrange(desc(p)) %>%
  ggplot(aes(reorder(account, p), p, size=n)) +
  geom_point() + coord_flip() + theme_light() +
  xlab("Account") +
  ylab("Proposal win rate")
```

A number of observations:

1. What are the differences between accounts with win rates between (0.6 and 0.8) and (0.8 and 1.0)?


* **Seasonality in win rates**: we experience seasonality in the number of proposals we respond to. Let's explore number of proposals per year and win rates per year

```{r explore seasonality}
# seasonal win rates by account and over practice
proposals %>%
  group_by(account, stage) %>%
  mutate(n = n()) %>%
  ungroup() %>%
  group_by(account) %>%
  mutate(p = n / sum(n)) %>%
  filter(stage == 1) %>%
  select(-amount, -offer, -sector, -segment, -director, -manager) %>%
  arrange(desc(p)) %>%
  ggplot(aes(reorder(creationDate, p), p, colour=n, alpha = 0.4)) +
  geom_point() +
  facet_wrap(~ practice) +
  theme_minimal() +
  xlab("Date") +
  ylab("Proposal win rate")
```

* **Overall win rates over time**
```{r overall win rates over time}
# TODO
```

* **Do smaller jobs lead to bigger jobs?**
Investigate a time effect of jobs to jobs within an account

```{r do smaller jobs lead to bigger jobs}
# find the accounts with the most proposals won
proposals %>%
  group_by(account, stage) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  top_n(10)

p1 <- proposals %>% filter(account == "account241") %>%
  ggplot(aes(creationDate, amount)) +
  geom_point() +
  theme_minimal()
  
p2 <- proposals %>%
  filter(stage == 1) %>%
  group_by(account) %>%
  select(account, amount, creationDate, practice, offer, source) %>%
  mutate(n = n()) %>%
  arrange(desc(n)) %>%
  filter(n >= 49)

p2 <- p2 %>%
  ggplot(aes(creationDate, amount, alpha=0.4)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal() +
  facet_wrap(~ account)

grid.arrange(p1, p2, ncol = 2)
rm(p1, p2)
```
As can be seen, the assumption that small jobs lead to bigger jobs seems implausible, at least for the 4 accounts with the most proposals won.

* **How does proposal size relates to number of proposals won by account?**
```{r proposals size over proposals won by account}
# find the average size of proposals won and relate this to the amount of proposals submitted
p1 <- proposals %>%
  filter(stage == 1) %>%
  group_by(account) %>%
  summarise(n = n(), avg_size = sum(amount) / n) %>%
  ggplot(aes(n, avg_size)) +
  geom_point() +
  geom_smooth(method = "loess") +
  theme_minimal() +
  xlab("Number of opps won per account") +
  ylab("Average amount of the opps")

p2 <- proposals %>%
  filter(stage == 1) %>%
  group_by(account) %>%
  summarise(n = n(), size = sum(amount)) %>%
  ggplot(aes(n, size)) +
  geom_point() +
  geom_smooth(method = "loess") +
  theme_minimal() +
  xlab("Number of opps won per account") +
  ylab("Total amount of the opps per account")

grid.arrange(p1, p2, ncol = 2)
rm(p1, p2)
```

It looks like there's no effect on the number of successful proposals per account and the average amount per proposal won. 


# Method

1. Try various ML approaches (prep data to suit the analysis)
2. Select potential model
3. Conduct analysis

# Analysis
Split data in a train and test set. The train set will contain 90% of the data.
```{r create train and test set}
# Create train and test set with standard seed for reproducibiliy
set.seed(1)

# Get a random sample of 90% for the train set and 10% for validation
train_index <- sample(1:nrow(proposals), round(0.9*nrow(proposals)))
train_set <- proposals[train_index, ]
test_set <- proposals[-train_index, ]

# clean up environment
rm(train_index) # clean up
```

## glm


## trees


## K nearest neighbours
K nearest neightbour performs well
```{r K nearest neighbours, cache=TRUE}
# K nearest neighbours
library(caret)

train_set_knn <- train_set %>%
  na.omit() %>%
  select(-creationDate, -closeDate, -account, -amount, -director, -manager)

test_set_knn <- train_set %>%
  na.omit() %>%
  select(-creationDate, -closeDate, -account, -amount, -director, -manager)


train_knn <- train(stage ~ ., method = "knn", 
                   data = train_set_knn,
                   na.action = na.pass,
                   tuneGrid = data.frame(k = seq(9, 71, 2)))

# best tune
train_knn$bestTune

confusionMatrix(predict(train_knn, test_set_knn, type = "raw"),
                test_set_knn$stage)$overall["Accuracy"]

```

Best accuracy: 0.7006897 

Are some pairs of directors and managers better than others?
```{r compare directors and managers as pairs}
# TODO
```


## rmse
An rmse approach has been tested under the assumption that there are effects for:

* account: some clients are more inclined to award work to us than others
* practice: some practices are more mature than others
* director: some directors win more proposals than others
* manager: some managers win more proposals than others
* source: the way proposals get to us impacts win rates (e.g. level of competitiveness, relationships)

## 


# Conclusions
